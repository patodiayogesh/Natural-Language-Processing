Yogesh Patodiayp2607@columbia.eduINPUTSThe file takes the following inputs:1. train: This contains the absolute path for the file containing training data. The file should be a '.jsonl' file. 2. test: This contains the absolute path for the file containing validation or test data. The file should be a '.jsonl' file.3. user: This contains the absolute path for the file containing user data. The file should be a '.json' file.4. model: The model the user wants to run. Allowed inputs are: *	Ngram*	Ngram+Lex*	Ngram+Lex+Ling*	Ngram+Lex+Ling+User5. lexicon_path: This contains the absolute path for the folder containing lexicon files. Please ensure that the VAD files follow the below structure. The classifier uses NRC-VAD-Lexicons for training.lexica  |-- NRC-VAD-Lexicon-Aug2018Release      |--- NRC-VAD-Lexicon.txt6. outfile: This contains the absolute path for the file where the user wants the predicted values to be saved.The file should be run from terminal with the following syntax: hw1.py --train <train path> --test <test path> --user_data <user path> --model <model> --lexicon_path <lexicon path> --outfile <outfile path>DESCRIPTIONNgram: The Ngram model is a unigram model. The model gives poor accuracy if it is trained on topics of just 'Religion' category. The model gives better results when it is trained on data irrespective of category. The data is separated into 'Pro' and 'Con' text. The Vocabulary is created on them together, but they are treated as separate features and separate vectors and created for each.Ngram+Lex: This model utilizes the unigram features mentioned above along with the NRC VAD lexicons. The model adds the Average Valence, Arousal, Dominance scores each for 'Pro' and 'Con' text. This model works on 6 more features as compared to the Ngram model. The increase in accuracy between this and Ngram model is very low, about 0.2%.Ngram+Lex+Ling: This model utilizes the Ngram+Lex features along with linguistic features of each pro and con text. Links to websites' and 'Personal Pronouns' are identified in the text and added as features each for 'Pro' and 'Con' text. This model works the best compared to all the other models. It gave an accuracy of around 74% on the validation set.Ngram+Lex+Ling+User: This model utilizes the Ngram+Lex+Ling features along with user data of each debater. 'Religious Ideology' and 'Ethnicity' were identified from the user data for each debater and as features. This model works better compared to 'Ngram+Lex' model but poorer than 'Ngram+Lex+Ling' model.BEST CLASSIFIERThe 'Ngram+Lex+Ling' classifier gives the highest accuracy compared to the other classifiers.OUTPUTThe classifier predictions are saved in the outfile path that the user mentions in the input.