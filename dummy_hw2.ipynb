{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51145c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Imports - our files\n",
    "import utils\n",
    "import models\n",
    "#import argparse\n",
    "\n",
    "# Global definitions - data\n",
    "DATA_FN = '/Users/neelampatodia/Desktop/Yogesh/NLP/Assignments/hw2/data/crowdflower_data.csv'\n",
    "LABEL_NAMES = [\"happiness\", \"worry\", \"neutral\", \"sadness\"]\n",
    "\n",
    "# Global definitions - architecture\n",
    "EMBEDDING_DIM = 100  # We will use pretrained 100-dimensional GloVe\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "USE_CUDA = torch.cuda.is_available()  # CUDA will be available if you are using the GPU image for this homework\n",
    "\n",
    "# Global definitions - saving and loading data\n",
    "FRESH_START = False  # set this to false after running once with True to just load your preprocessed data from file\n",
    "#                     (good for debugging)\n",
    "TEMP_FILE = \"temporary_data.pkl\"  # if you set FRESH_START to false, the program will look here for your data, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "336366f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DataLoaders and embeddings from file....\n"
     ]
    }
   ],
   "source": [
    "with open(TEMP_FILE, \"rb\") as f:\n",
    "    print(\"Loading DataLoaders and embeddings from file....\")\n",
    "    train_generator, dev_generator, test_generator, embeddings, train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be06551",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-7b63e9cae233>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtrain_generator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdev_generator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_generator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_generator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "train_generator, dev_generator, test_generator, embeddings, train_data\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa79e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, pre_trained_embeddings):\n",
    "        super(DenseNetwork).__init__()\n",
    "        self.embedding_layer = nn.Embedding(pre_trained_embeddings.shape[0],\n",
    "                                            pre_trained_embeddings.shape[1])\n",
    "        self.embedding_layer.weight.data.copy_(pre_trained_embeddings)\n",
    "        #self.cnn_layer = nn.Conv2d(x.size(1),int(x.size(1)/2),(x.size(0),2), stride=1)\n",
    "        \n",
    "        self.pooling_layer = nn.LPPool2d(norm_type=1,kernel_size=(91,1), stride = 1)\n",
    "        self.layer1 = nn.Linear(input_size,hidden_size)\n",
    "        self.activation_func = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding_layer(x)\n",
    "        pooling_layer = nn.AvgPool2d(kernel_size=(x.size(1),1), stride = 1)\n",
    "        output = pooling_layer(output)\n",
    "        output = output.squeeze()\n",
    "        output = self.layer1(output)\n",
    "        output = self.activation_func(output)\n",
    "        output = self.layer2(output)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b75fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, pre_trained_embeddings, num_filters, filter_sizes, output_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding.pre_trained_embeddings.shape[1])\n",
    "        self.embedding_layer.weight.data.copy_(pre_trained_embeddings)\n",
    "        self.conv_layer = nn.ModuleList([nn.Conv2d(\n",
    "                                                in_channels = 1,\n",
    "                                                out_channels = num_filters,\n",
    "                                                kernel_size = (fs, 100)) for fs in filter_sizes])\n",
    "        self.layer1 = nn.Linear(len(filter_sizes)*num_filters, output_dim)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.embedding_layer(x)\n",
    "        output = output.unsqueeze(1)\n",
    "        output = [F.relu(conv(output)).squeeze(3) for conv in self.conv_layer]\n",
    "        output = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in output]\n",
    "        output = self.dropout_layer(torch.cat(output, dim = 1))\n",
    "        output = self.layer1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbdeb9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17752, 100])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = None, None\n",
    "for x,y in dev_generator:\n",
    "    a=x\n",
    "    b=y\n",
    "    print(a.size(1), b.shape)\n",
    "    break\n",
    "z = torch.sum(a,)\n",
    "z.shape\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71ce76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "import torch.optim as optim\n",
    "#model = DenseNetwork(100,10,4,embeddings)\n",
    "model = CNN(embeddings, 100, [2,3,4], 4,0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lambda1 = lambda epoch: 0.65 ** 100\n",
    "#scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda = lambda epoch: 0.95 )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2551683",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc446c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:47<1:18:57, 47.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0 tensor([24.6769]) tensor([75.3231])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [01:35<1:18:02, 47.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1 tensor([23.6988]) tensor([0.9781])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [02:23<1:57:19, 71.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2 tensor([23.7946]) tensor([0.0958])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "development_loss = 100.0\n",
    "for n in tqdm.tqdm(range(100)):\n",
    "    avg_loss = []\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    for x, y in train_generator:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, y)\n",
    "        avg_loss.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*x.size(0)\n",
    "    \n",
    "    gold = []\n",
    "    predicted = []\n",
    "    # Keep track of the loss\n",
    "    loss = torch.zeros(1)  # requires_grad = False by default; float32 by default\n",
    "    if USE_CUDA:\n",
    "        loss = loss.cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_b, y_b in dev_generator:\n",
    "            y_pred = model(X_b)\n",
    "            # Save gold and predicted labels for F1 score - take the argmax to convert to class labels\n",
    "            gold.extend(y_b.cpu().detach().numpy())\n",
    "            predicted.extend(y_pred.argmax(1).cpu().detach().numpy())\n",
    "            loss += loss_fn(y_pred.double(), y_b.long()).data\n",
    "    print('loss',n, loss, abs(development_loss-loss))\n",
    "    #scheduler.step()\n",
    "    if development_loss<loss:\n",
    "        break\n",
    "    development_loss = loss\n",
    "    m = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "838d6433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0c66abfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNetwork(\n",
       "  (embedding_layer): Embedding(17752, 100)\n",
       "  (pooling_layer): LPPool2d(norm_type=1, kernel_size=(91, 1), stride=1, ceil_mode=False)\n",
       "  (layer1): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (activation_func): ReLU()\n",
       "  (layer2): Linear(in_features=10, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aefb0d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.LPPool2d(1,kernel_size=(91,1),stride=1)\n",
    "pooled_data = pool(e_data)\n",
    "pooled_data.shape\n",
    "p_squeezed_data=pooled_data.squeeze()\n",
    "p_squeezed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34fcce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loss_fn, test_generator):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on the development set, providing the loss and macro F1 score.\n",
    "    :param model: a model that performs 4-way emotion classification\n",
    "    :param loss_fn: a function that can calculate loss between the predicted and gold labels\n",
    "    :param test_generator: a DataLoader that provides batches of the testing set\n",
    "    \"\"\"\n",
    "    gold = []\n",
    "    predicted = []\n",
    "\n",
    "    # Keep track of the loss\n",
    "    loss = torch.zeros(1)  # requires_grad = False by default; float32 by default\n",
    "    if USE_CUDA:\n",
    "        loss = loss.cuda()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate over batches in the test dataset\n",
    "    with torch.no_grad():\n",
    "        for X_b, y_b in test_generator:\n",
    "            # Predict\n",
    "            y_pred = model(X_b)\n",
    "\n",
    "            # Save gold and predicted labels for F1 score - take the argmax to convert to class labels\n",
    "            gold.extend(y_b.cpu().detach().numpy())\n",
    "            predicted.extend(y_pred.argmax(1).cpu().detach().numpy())\n",
    "\n",
    "            loss += loss_fn(y_pred.double(), y_b.long()).data\n",
    "\n",
    "    # Print total loss and macro F1 score\n",
    "    print(\"Test loss: \")\n",
    "    print(loss)\n",
    "    print(\"F-score: \")\n",
    "    print(f1_score(gold, predicted, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "be6025ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNetwork(\n",
       "  (embedding_layer): Embedding(17752, 100)\n",
       "  (pooling_layer): LPPool2d(norm_type=1, kernel_size=(91, 1), stride=1, ceil_mode=False)\n",
       "  (layer1): Linear(in_features=100, out_features=20, bias=True)\n",
       "  (activation_func): ReLU()\n",
       "  (layer2): Linear(in_features=20, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45875339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: \n",
      "tensor([24.4684])\n",
      "F-score: \n",
      "0.4887734851408822\n"
     ]
    }
   ],
   "source": [
    "test_model(m, loss_fn, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6fa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}